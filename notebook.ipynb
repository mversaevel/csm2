{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4147b6da",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Initialize, import libraries and load data, clean data \"\"\"\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "\n",
    "from itertools import combinations\n",
    "from scipy import stats\n",
    "from statsmodels.tsa.api import VAR\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "import ast\n",
    "import pickle\n",
    "\n",
    "import utils\n",
    "import var_decomposition\n",
    "\n",
    "\n",
    "output_path = 'rmarkdown/run4-mimicking_addl/'\n",
    "\n",
    "\n",
    "# load market data\n",
    "files_to_load = [\n",
    "    'BAA10Y', # default spread between BAA-rated corporate bonds and 10-year Treasury bonds\n",
    "    'T10Y3M', # term spread between 10-year Treasury bonds and 3-month Treasury bills\n",
    "    'DTB4WK', # 4-week Treasury bill rate - used as a proxy for the risk-free rate\n",
    "    'DTB3' # 3-month Treasury bill rate\n",
    "]\n",
    "collected_market_data = []\n",
    "for filename in files_to_load:\n",
    "    data = pd.read_csv(f'data/{filename}.csv')\n",
    "    data['observation_date'] = pd.to_datetime(data['observation_date']) + pd.offsets.MonthEnd(0) #- pd.offsets.Day(1)\n",
    "    data = data.rename(columns={\n",
    "        'observation_date': 'Date',\n",
    "    }).set_index('Date')\n",
    "    collected_market_data.append(data)\n",
    "\n",
    "df_market_data = pd.concat(collected_market_data, axis=1)\n",
    "df_market_data['BAA10Y'] /= 100\n",
    "df_market_data['T10Y3M'] /= 100\n",
    "df_market_data['DTB3'] /= 100\n",
    "df_market_data['DTB4WK_LOG'] = np.log(1 + df_market_data['DTB4WK'] / 100) # make percentage, take log, add 1 to avoid log(0)\n",
    "df_market_data['DTB4WK'] /= 100\n",
    "\n",
    "CAPE = pd.read_excel('data/ie_data.xls', sheet_name='Data', skiprows=7, header=0)[['Date', 'CAPE']]\n",
    "CAPE = CAPE.dropna()\n",
    "\n",
    "date_year_month = CAPE['Date'].astype(str).str.split('.')\n",
    "CAPE['Date'] = pd.to_datetime(date_year_month.apply(lambda x: f\"{x[0]}.{x[1] if len(x[1]) == 2 else f'{x[1]}0'}\"), format='%Y.%m') # fix october month which is parsed as YYYY.01 instead of YYYY.10\n",
    "CAPE['Date'] = CAPE['Date'] + pd.offsets.MonthEnd(0)\n",
    "CAPE['CAPE'] = np.log(CAPE['CAPE'])  # Taking the log of CAPE for normalization\n",
    "CAPE = CAPE.set_index('Date')\n",
    "\n",
    "df_market_data = df_market_data.join(CAPE, how='left')\n",
    "df_market_data = df_market_data[~df_market_data.index.duplicated(keep='first')]\n",
    "\n",
    "# load CSM index data\n",
    "data_path = 'data/index_data/'\n",
    "\n",
    "with open(data_path + 'run4-mimicking.pkl', 'rb') as f:\n",
    "    results = pickle.load(f)\n",
    "\n",
    "trad_country_returns = results[\"trad_country_returns\"]\n",
    "trad_country_returns_EW = results[\"trad_country_returns_EW\"]\n",
    "csm_returns = results[\"csm_returns\"]\n",
    "\n",
    "trad_country_returns_excess = utils.calc_excess_returns(trad_country_returns, df_market_data, 'DTB4WK', log_returns=False)\n",
    "trad_country_returns_EW_excess = utils.calc_excess_returns(trad_country_returns_EW, df_market_data, 'DTB4WK', log_returns=False)\n",
    "csm_returns_excess = utils.calc_excess_returns(csm_returns, df_market_data, 'DTB4WK', log_returns=False)\n",
    "\n",
    "trad_country_returns_excess_log = utils.calc_excess_returns(trad_country_returns, df_market_data, 'DTB4WK_LOG', log_returns=True)\n",
    "trad_country_returns_EW_excess_log = utils.calc_excess_returns(trad_country_returns_EW, df_market_data, 'DTB4WK_LOG', log_returns=True)\n",
    "csm_returns_excess_log = utils.calc_excess_returns(csm_returns, df_market_data, 'DTB4WK_LOG', log_returns=True)\n",
    "\n",
    "# for VAR data, always use log returns!\n",
    "data_VAR_full = df_market_data.join(\n",
    "    csm_returns_excess_log.add_prefix('csm_'), how='inner'\n",
    ").join(\n",
    "    trad_country_returns_excess_log.add_prefix('trad_'), how='inner'\n",
    ")\n",
    "\n",
    "# Create local state variable dataframe\n",
    "data_var_full_incl_local_state_vars = data_VAR_full.copy()\n",
    "OECD_data = utils.load_OECD_data(\n",
    "    path_and_filename='./data/OECD.SDD.STES,DSD_STES@DF_CLI,+all.csv'\n",
    ")\n",
    "\n",
    "CLI_LOG_SCALE = False\n",
    "for country in OECD_data['Country'].unique():\n",
    "    df = OECD_data[OECD_data['Country'] == country]\n",
    "    df = df.rename(columns={'CLI': f'CLI_{country}'})\n",
    "\n",
    "    if CLI_LOG_SCALE:\n",
    "        df[f'CLI_{country}'] = np.log(df[f'CLI_{country}'])\n",
    "\n",
    "    data_var_full_incl_local_state_vars = data_var_full_incl_local_state_vars.join(\n",
    "        df.set_index('Date')[f'CLI_{country}'], how='left'\n",
    "    )\n",
    "\n",
    "# for robustness, use EW trad countries returns \n",
    "RC_data_VAR_full_EW = df_market_data.join(\n",
    "    csm_returns_excess_log.add_prefix('csm_'), how='inner'\n",
    ").join(\n",
    "    trad_country_returns_EW_excess_log.add_prefix('trad_'), how='inner'\n",
    ")\n",
    "\n",
    "data_VAR_world = data_VAR_full.copy()\n",
    "data_VAR_world['trad_wld'] = data_VAR_full[[col for col in data_VAR_full.columns if col.startswith('trad_')]].mean(axis=1)\n",
    "data_VAR_world['csm_wld'] = data_VAR_full[[col for col in data_VAR_full.columns if col.startswith('csm_')]].mean(axis=1)\n",
    "data_VAR_world = data_VAR_world[[\n",
    "    'csm_wld',\n",
    "    'trad_wld',\n",
    "    'BAA10Y',\n",
    "    'T10Y3M',\n",
    "    'DTB3',\n",
    "    'DTB4WK_LOG',\n",
    "    'CAPE'\n",
    "]]\n",
    "\n",
    "COUNTRIES_OF_INTEREST = results['optim_description'].loc[results['optim_description']['Unnamed: 0'] == 'countries_for_optimization', '0'].values[0]\n",
    "COUNTRIES_OF_INTEREST = ast.literal_eval(COUNTRIES_OF_INTEREST)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddb5d1dc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4249d857",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b829276",
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_to_iterate = {\n",
    "    'CSM index': csm_returns,\n",
    "    'Trad country index': trad_country_returns\n",
    "}\n",
    "long_run_corr_results = {}\n",
    "\n",
    "for index_type, return_series in dict_to_iterate.items():\n",
    "    \n",
    "    return_series_period1 = return_series.iloc[0:return_series.shape[0]//2, :]\n",
    "    return_series_period2 = return_series.iloc[return_series.shape[0]//2:, :]\n",
    "\n",
    "    cols = return_series.columns\n",
    "    period1_pairs = []\n",
    "    period2_pairs = []\n",
    "    for a, b in combinations(cols, 2):\n",
    "        period1_corr = return_series_period1[a].corr(return_series_period1[b])\n",
    "        period2_corr = return_series_period2[a].corr(return_series_period2[b])\n",
    "\n",
    "        period1_pairs.append({'pair': f'{a}-{b}', 'corr_period1': period1_corr})\n",
    "        period2_pairs.append({'pair': f'{a}-{b}', 'corr_period2': period2_corr})\n",
    "\n",
    "    pairwise_corrs_period1 = pd.DataFrame(period1_pairs).set_index('pair')\n",
    "    pairwise_corrs_period2 = pd.DataFrame(period2_pairs).set_index('pair')\n",
    "\n",
    "    # combined_corrs = pd.concat([pairwise_corrs_period1, pairwise_corrs_period2], axis=0)\n",
    "    combined_corrs = pd.concat([pairwise_corrs_period1, pairwise_corrs_period2], axis=1)\n",
    "    combined_corrs.sort_values(by='corr_period1', ascending=False)\n",
    "\n",
    "    # Create a figure and axis\n",
    "    fig, ax = plt.subplots()\n",
    "    x = np.arange(len(combined_corrs))\n",
    "    \n",
    "    plt.scatter(x, combined_corrs['corr_period1'], alpha=0.7, s=30, color='tab:orange')\n",
    "    plt.scatter(x, combined_corrs['corr_period2'], alpha=0.7, s=30, color='tab:blue')\n",
    "    plt.axhline(y=(combined_corrs['corr_period1']).mean(), color='tab:orange', linestyle='--')\n",
    "    plt.axhline(y=(combined_corrs['corr_period2']).mean(), color='tab:blue', linestyle='--')\n",
    "    plt.xticks(x, combined_corrs.index, rotation=90)\n",
    "    plt.legend(['Period 1', 'Period 2'], loc='best')\n",
    "    plt.xlabel('Country pair')\n",
    "    plt.ylabel('Correlation')\n",
    "    plt.title(f'Pairwise correlations: Period 1 vs Period 2 (for {index_type})')\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    model = stats.ttest_rel(\n",
    "        pairwise_corrs_period1.to_numpy(), \n",
    "        pairwise_corrs_period2.to_numpy(), \n",
    "        alternative='greater'\n",
    "    )\n",
    "\n",
    "    fig.savefig(f'{output_path}fig_pairwise_corrs_{index_type.replace(\" \", \"_\").lower()}.png', bbox_inches='tight')\n",
    "\n",
    "    result = {\n",
    "        'index_type': index_type,\n",
    "        'mean_corr_period1': pairwise_corrs_period1.mean().values[0],\n",
    "        'mean_corr_period2': pairwise_corrs_period2.mean().values[0],\n",
    "        't_statistic': model.statistic[0],\n",
    "        'p_value': model.pvalue[0],\n",
    "        'df': model.df[0],\n",
    "        #'matplotlib_figure': fig,\n",
    "    }\n",
    "    result_as_df = pd.DataFrame.from_dict(result, orient='index', columns=['value']).T\n",
    "\n",
    "    if index_type == 'CSM index':\n",
    "        long_run_corr_results['csm'] = result_as_df\n",
    "    elif index_type == 'Trad country index':\n",
    "        long_run_corr_results['trad'] = result_as_df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "338cb3e4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75c8e70f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f0c6c9a0",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fc3b1016",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5faaf694",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb8d0cfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "spanning_results_separate_regressions = {}\n",
    "for country in csm_returns_excess.columns:\n",
    "    X = sm.add_constant(trad_country_returns_excess[country])\n",
    "    y = csm_returns_excess[country]\n",
    "    model = sm.OLS(y, X).fit()\n",
    "    spanning_results_separate_regressions[country] = model\n",
    "\n",
    "pd.set_option('display.float_format', lambda x: '%.6f' % x)\n",
    "\n",
    "spanning_results_separate_regressions_results = {}\n",
    "for test_asset, model in spanning_results_separate_regressions.items():\n",
    "    # print(model.summary())\n",
    "    result = {\n",
    "        'coeffs': model.params,\n",
    "        'std_errors': model.HC0_se,\n",
    "        'tvalues': model.tvalues,\n",
    "        'pvalues': model.pvalues,\n",
    "        'r_squared': model.rsquared,\n",
    "    }\n",
    "    result = pd.DataFrame.from_dict(result).reset_index()\n",
    "    spanning_results_separate_regressions_results[test_asset] = result\n",
    "\n",
    "spanning_results_separate_regressions_results = pd.concat(\n",
    "    {k: v.set_index('index') for k, v in spanning_results_separate_regressions_results.items()},\n",
    "    names=['country', 'variable']\n",
    ")\n",
    "\n",
    "spanning_results_separate_regressions_results.reset_index()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc67a2b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# input for multivariate GRS\n",
    "\n",
    "spanning_results_multivariate_per_country = {}\n",
    "for country in csm_returns_excess.columns:\n",
    "    X = sm.add_constant(trad_country_returns_excess)\n",
    "    y = csm_returns_excess[country]\n",
    "    model = sm.OLS(y, X).fit()\n",
    "    spanning_results_multivariate_per_country[country] = model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb7f72da",
   "metadata": {},
   "outputs": [],
   "source": [
    "## GRS test:\n",
    "\n",
    "GRS_test_result = utils.grs_test(\n",
    "    resid=np.array([model.resid for model in spanning_results_multivariate_per_country.values()]).T,\n",
    "    alpha=np.array([model.params['const'] for model in spanning_results_multivariate_per_country.values()]).reshape(-1, 1),\n",
    "    factors=np.array(trad_country_returns_excess)  \n",
    ")\n",
    "\n",
    "spanning_results_multivariate_per_country_GRS = pd.DataFrame({\n",
    "    'GRS_F_statistic': GRS_test_result[0],\n",
    "    'GRS_p_value': GRS_test_result[1]\n",
    "}, index=[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6822106f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed1891c0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a315f39a",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36e2dbca",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3e79a0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import create_efficient_frontier\n",
    "\n",
    "csm_mean_returns = csm_returns.mean().values\n",
    "csm_cov_matrix = csm_returns.cov()\n",
    "\n",
    "trad_mean_returns = trad_country_returns.mean().values\n",
    "trad_cov_matrix = trad_country_returns.cov()\n",
    "\n",
    "trad_mean_returns_EW = trad_country_returns_EW.mean().values\n",
    "trad_cov_matrix_EW = trad_country_returns_EW.cov()\n",
    "\n",
    "combined_returns = pd.concat([csm_returns, trad_country_returns], axis=1)\n",
    "combined_mean_returns = combined_returns.mean().values\n",
    "combined_cov_matrix = combined_returns.cov()\n",
    "\n",
    "ef_csm = create_efficient_frontier(csm_mean_returns, csm_cov_matrix, n_points=150)\n",
    "ef_trad = create_efficient_frontier(trad_mean_returns, trad_cov_matrix, n_points=150)\n",
    "ef_trad_EW = create_efficient_frontier(trad_mean_returns_EW, trad_cov_matrix_EW, n_points=150)\n",
    "ef_combined = create_efficient_frontier(combined_mean_returns, combined_cov_matrix, n_points=150)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02929a11",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(8, 6))\n",
    "plt.plot(ef_csm.volatility * 100, ef_csm.returns * 100, label='Efficient Frontier csm', color='blue', linestyle='-')\n",
    "plt.plot(ef_trad.volatility * 100, ef_trad.returns * 100, label='Efficient Frontier trad', color='red', linestyle='-')\n",
    "plt.plot(ef_trad_EW.volatility * 100, ef_trad_EW.returns * 100, label='Efficient Frontier trad (equal weighted)', color='orange', linestyle='--')\n",
    "plt.plot(ef_combined.volatility * 100, ef_combined.returns * 100, label='Efficient Frontier combined', color='green', linestyle='--')\n",
    "plt.xlabel('Portfolio Volatility (Std. Dev. of monthly returns %)')\n",
    "plt.ylabel('Portfolio Return (monthly %)')\n",
    "plt.legend(loc='upper left')\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "fig.savefig(f'{output_path}fig_efficient_frontiers.png', bbox_inches='tight')\n",
    "\n",
    "mean_variance_frontiers = { \n",
    "    'trad': ef_trad,\n",
    "    'trad_EW': ef_trad_EW,\n",
    "    'csm': ef_csm,\n",
    "    'combined': ef_combined,\n",
    "    #'matplotlib_figure': fig,\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee3bfdca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c798b51",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "eddbe6f0",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e98dc843",
   "metadata": {},
   "outputs": [],
   "source": [
    "import simulations\n",
    "\n",
    "# load data\n",
    "results_quantiles = pd.read_csv('data/simulations_results_quantiles_n_runs_10000.csv', index_col=0)\n",
    "simulations.plot_sim_results(results_quantiles, metric=\"std_dev\", n_runs=10000, list_of_quantiles=[0.5], facet_plot=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b76a221c",
   "metadata": {},
   "outputs": [],
   "source": [
    "### normalized by convergence values\n",
    "\n",
    "import simulations\n",
    "results_quantiles = pd.read_csv('data/simulations_results_quantiles_n_runs_10000.csv', index_col=0)\n",
    "\n",
    "simulations.plot_sim_results(results_quantiles, metric=\"std_dev\", n_runs=10000, list_of_quantiles=None, facet_plot=True, use_convergence_type=False, show_plot=False)\n",
    "fig_simulations_std_dev = plt.gcf()\n",
    "plt.close(fig_simulations_std_dev)\n",
    "\n",
    "results_quantiles_normalized_convergence = simulations.get_convergence_normalized_results(results_quantiles=results_quantiles)\n",
    "\n",
    "simulations.plot_sim_results(results_quantiles_normalized_convergence, metric=\"std_dev\", n_runs=10000, list_of_quantiles=None, facet_plot=False, use_convergence_type=True, show_plot=False)\n",
    "fig_simulations_std_dev_convergence = plt.gcf()\n",
    "plt.close(fig_simulations_std_dev_convergence)\n",
    "\n",
    "\n",
    "sim_results = {\n",
    "    \"fig_simulations_std_dev\": fig_simulations_std_dev,\n",
    "    \"fig_simulations_std_dev_convergence\": fig_simulations_std_dev_convergence,\n",
    "}\n",
    "\n",
    "fig_simulations_std_dev.savefig(f'{output_path}fig_simulations_std_dev.png', bbox_inches='tight')\n",
    "fig_simulations_std_dev_convergence.savefig(f'{output_path}fig_simulations_std_dev_convergence.png', bbox_inches='tight')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33b30d7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import simulations\n",
    "\n",
    "# load data\n",
    "results_quantiles = pd.read_csv('data/simulations_results_quantiles_n_runs_10000.csv', index_col=0)\n",
    "simulations.plot_sim_results(results_quantiles, metric=\"std_dev\", n_runs=10000, list_of_quantiles=None, facet_plot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa0e6359",
   "metadata": {},
   "outputs": [],
   "source": [
    "import simulations\n",
    "\n",
    "# load data\n",
    "results_quantiles = pd.read_csv('data/simulations_results_quantiles_n_runs_10000.csv', index_col=0)\n",
    "simulations.plot_sim_results(results_quantiles, metric=\"sharpe_ratio\", n_runs=10000, list_of_quantiles=None, facet_plot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b955386",
   "metadata": {},
   "source": [
    "We can visually interpret these results as follows. Let's first look at the change in standard deviation as the number of countries in portfolio increases. We are not directly interested in absolute levels (these are slightly higher on average for CSM indices), we want to look at the shape of each graph and compare that. So this graph, for the CSM indices, starts at around 6.8% (for 2 countries) and ends at 5.9%. This is a decrease of 14%. For the trad indices, the curve starts at 6% (for 2 countries) and ends at 5.4%. This is a decrease of 10%. Moreover, the curve for the traditional country indices seems to be slightly more concave, meaning it approaches the asymptote faster. \n",
    "\n",
    "These results suggests that the diversification benefits of traditional country indices are depleted faster. It takes fewer different countries in the index to obtain a decrease in portfolio risk similar to holding all countries. A flipside of this observation is that one could say that these traditional country indices are more alike. For the CSM indices, it takes more countries to approximate the portfolio standard deviation of the full set of countries. This suggests that CSM indices are more different from one another than traditional country indices are.\n",
    "\n",
    "The statistics mentioned above in the text are summarized in the table below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a828f96",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_quantiles = pd.read_csv('data/simulations_results_quantiles_n_runs_10000.csv', index_col=0)\n",
    "csm_median_stddev_start = results_quantiles[(results_quantiles['dataset'] == 'csm') & (results_quantiles.index == 0.5) & (results_quantiles['num_countries'] == 2)]['std_dev']\n",
    "csm_median_stddev_end = results_quantiles[(results_quantiles['dataset'] == 'csm') & (results_quantiles.index == 0.5) & (results_quantiles['num_countries'] == 16)]['std_dev']\n",
    "\n",
    "trad_median_stddev_start = results_quantiles[(results_quantiles['dataset'] == 'trad') & (results_quantiles.index == 0.5) & (results_quantiles['num_countries'] == 2)]['std_dev']\n",
    "trad_median_stddev_end = results_quantiles[(results_quantiles['dataset'] == 'trad') & (results_quantiles.index == 0.5) & (results_quantiles['num_countries'] == 16)]['std_dev']\n",
    "\n",
    "pd.DataFrame({\n",
    "    'CSM': \n",
    "    {\n",
    "        'median_stddev_start (N=2)': csm_median_stddev_start.values[0],\n",
    "        'median_stddev_end (N=16)': csm_median_stddev_end.values[0],\n",
    "        'relative_change': csm_median_stddev_end.values[0] / csm_median_stddev_start.values[0] - 1\n",
    "    },\n",
    "    'Traditional': \n",
    "    {\n",
    "        'median_stddev_start (N=2)': trad_median_stddev_start.values[0],\n",
    "        'median_stddev_end (N=16)': trad_median_stddev_end.values[0],\n",
    "        'relative_change': trad_median_stddev_end.values[0] / trad_median_stddev_start.values[0] - 1\n",
    "    }\n",
    "})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f739cc4",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "009ddc0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07519497",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_VAR_world_trad = data_VAR_world[\n",
    "    [\n",
    "        \"trad_wld\",\n",
    "        \"BAA10Y\",\n",
    "        \"T10Y3M\",\n",
    "        \"DTB3\",\n",
    "        \"CAPE\"\n",
    "    ]\n",
    "]\n",
    "\n",
    "N_CF, N_DR, results = var_decomposition.get_var_decomp(data_VAR_world_trad)\n",
    "\n",
    "corr_mat = np.corrcoef(N_CF, N_DR)\n",
    "std_N_CF = np.std(N_CF)\n",
    "std_N_DR = np.std(N_DR)\n",
    "np.fill_diagonal(corr_mat, [std_N_CF, std_N_DR])\n",
    "campbell_DF_trad_world = pd.DataFrame(corr_mat, index=['CF', 'DR'], columns=['CF', 'DR']).round(4)\n",
    "campbell_DF_trad_world"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39ea1a39",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_VAR_world_csm = data_VAR_world[\n",
    "    [\n",
    "        \"csm_wld\",\n",
    "        \"BAA10Y\",\n",
    "        \"T10Y3M\",\n",
    "        \"DTB3\",\n",
    "        \"CAPE\"\n",
    "    ]\n",
    "]\n",
    "\n",
    "\n",
    "N_CF, N_DR, results = var_decomposition.get_var_decomp(data_VAR_world_csm)\n",
    "\n",
    "corr_mat = np.corrcoef(N_CF, N_DR)\n",
    "std_N_CF = np.std(N_CF)\n",
    "std_N_DR = np.std(N_DR)\n",
    "np.fill_diagonal(corr_mat, [std_N_CF, std_N_DR])\n",
    "campbell_DF_csm_world = pd.DataFrame(corr_mat, index=['CF', 'DR'], columns=['CF', 'DR']).round(4)\n",
    "campbell_DF_csm_world\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97c96356",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e3676a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "N_CF_trad_global, N_DR_trad_global, results_trad_global = var_decomposition.get_var_decomp(data_VAR_world_trad)\n",
    "N_CF_csm_global, N_DR_csm_global, results_csm_global = var_decomposition.get_var_decomp(data_VAR_world_csm)\n",
    "\n",
    "df_for_plot_world = pd.DataFrame({\n",
    "    'Date': data_VAR_world_trad.reset_index()['Date'][:-1],\n",
    "    'N_CF_trad_global': N_CF_trad_global,\n",
    "    'N_DR_trad_global': N_DR_trad_global,\n",
    "    'N_CF_csm_global': N_CF_csm_global,\n",
    "    'N_DR_csm_global': N_DR_csm_global,\n",
    "})\n",
    "\n",
    "fig, axes = plt.subplots(2, 1, figsize=(16, 6), sharey=True)\n",
    "\n",
    "facet_info = [\n",
    "    ('N_CF_trad_global', 'N_DR_trad_global', 'Traditional Index'),\n",
    "    ('N_CF_csm_global', 'N_DR_csm_global', 'CSM Index')\n",
    "]\n",
    "\n",
    "for ax, (cf_col, dr_col, title) in zip(axes, facet_info):\n",
    "    ax.plot(df_for_plot_world['Date'], df_for_plot_world[cf_col], label='a. Cashflow News', color='tab:blue', linestyle='-')\n",
    "    ax.plot(df_for_plot_world['Date'], df_for_plot_world[dr_col], label='b. Discount Rate News', color='tab:orange', linestyle='--')\n",
    "    ax.set_title(title)\n",
    "    # if ax is axes[0]:\n",
    "    #     ax.set_xlabel('Date')\n",
    "    ax.grid(True)\n",
    "    ax.set_ylabel('News Component')\n",
    "    ax.legend()\n",
    "\n",
    "plt.suptitle('Cashflow and Discount Rate News: Trad and CSM')\n",
    "plt.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
    "plt.show()\n",
    "\n",
    "var_decomp_results_global = {\n",
    "    'campbell_DF_trad_world': campbell_DF_trad_world,\n",
    "    'campbell_DF_csm_world': campbell_DF_csm_world,\n",
    "    'df_for_plot_world': df_for_plot_world\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e68f685",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92c9eab6",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_dict_trad = {}\n",
    "result_dict_csm = {}\n",
    "for country in COUNTRIES_OF_INTEREST:\n",
    "    data_VAR_trad = data_VAR_full[[\n",
    "        f\"trad_{country}\",\n",
    "        \"BAA10Y\",\n",
    "        \"T10Y3M\",\n",
    "        \"DTB3\",\n",
    "        \"CAPE\"\n",
    "    ]]\n",
    "\n",
    "    data_VAR_csm = data_VAR_full[[\n",
    "        f\"csm_{country}\",\n",
    "        \"BAA10Y\",\n",
    "        \"T10Y3M\",\n",
    "        \"DTB3\",\n",
    "        \"CAPE\"\n",
    "    ]]\n",
    "\n",
    "    trad_N_CF, trad_N_DR, trad_results = var_decomposition.get_var_decomp(data_VAR_trad)\n",
    "    csm_N_CF, csm_N_DR, csm_results = var_decomposition.get_var_decomp(data_VAR_csm)\n",
    "\n",
    "    trad_corr_mat = np.corrcoef(trad_N_CF, trad_N_DR)\n",
    "    trad_std_N_CF = np.std(trad_N_CF)\n",
    "    trad_std_N_DR = np.std(trad_N_DR)\n",
    "    np.fill_diagonal(trad_corr_mat, [trad_std_N_CF, trad_std_N_DR])\n",
    "    trad_corr_mat_df = pd.DataFrame(trad_corr_mat, index=['CF', 'DR'], columns=['CF', 'DR']).round(4)\n",
    "\n",
    "    csm_corr_mat = np.corrcoef(csm_N_CF, csm_N_DR)\n",
    "    csm_std_N_CF = np.std(csm_N_CF)\n",
    "    csm_std_N_DR = np.std(csm_N_DR)\n",
    "    np.fill_diagonal(csm_corr_mat, [csm_std_N_CF, csm_std_N_DR])\n",
    "    csm_corr_mat_df = pd.DataFrame(csm_corr_mat, index=['CF', 'DR'], columns=['CF', 'DR']).round(4)\n",
    "\n",
    "    result_dict_trad[country] = {\n",
    "        'cash flow': trad_std_N_CF,\n",
    "        'discount_rate': trad_std_N_DR\n",
    "    }\n",
    "\n",
    "    result_dict_csm[country] = {\n",
    "        'cash flow': csm_std_N_CF,\n",
    "        'discount_rate': csm_std_N_DR\n",
    "    }\n",
    "\n",
    "    # result_dict[country] = {\n",
    "    #     'trad': {\n",
    "    #         'corr_matrix': trad_corr_mat_df,\n",
    "    #         # 'N_CF': trad_N_CF,\n",
    "    #         # 'N_DR': trad_N_DR,\n",
    "    #         # 'results': trad_results\n",
    "    #     },\n",
    "    #     'csm': {\n",
    "    #         'corr_matrix': csm_corr_mat_df,\n",
    "    #         # 'N_CF': csm_N_CF,\n",
    "    #         # 'N_DR': csm_N_DR,\n",
    "    #         # 'results': csm_results\n",
    "    #     }\n",
    "    # }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f56d37a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9354105f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.DataFrame.from_dict(result_dict_trad, orient='index', columns=['cash flow', 'discount_rate']).rename(columns={\n",
    "    'cash flow': 'cash flow_trad',\n",
    "    'discount_rate': 'discount_rate_trad'\n",
    "})\n",
    "df1['CF_to_DR_ratio_trad'] = df1['cash flow_trad'] - df1['discount_rate_trad']\n",
    "\n",
    "df2 = pd.DataFrame.from_dict(result_dict_csm, orient='index', columns=['cash flow', 'discount_rate']).rename(columns={\n",
    "    'cash flow': 'cash flow_csm',\n",
    "    'discount_rate': 'discount_rate_csm'\n",
    "})\n",
    "df2['CF_to_DR_ratio_csm'] = df2['cash flow_csm'] - df2['discount_rate_csm']\n",
    "\n",
    "df_combined = pd.concat([df1, df2], axis=1)\n",
    "df_combined['CF_to_DR_ratio_diff'] = df_combined['CF_to_DR_ratio_csm'] - df_combined['CF_to_DR_ratio_trad']\n",
    "df_combined\n",
    "\n",
    "# df_combined['CF_to_DR_ratio_diff'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa9713c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hypothesis testing\n",
    "\n",
    "series_A = df_combined['CF_to_DR_ratio_trad'].to_numpy()\n",
    "series_B = df_combined['CF_to_DR_ratio_csm'].to_numpy()\n",
    "\n",
    "# t_statistic, p_value = stats.ttest_ind(series_A, series_B, equal_var=False)\n",
    "t_statistic, p_value = stats.ttest_rel(series_B, series_A, alternative='two-sided')\n",
    "\n",
    "print(f\"T-statistic: {t_statistic}\")\n",
    "print(f\"p-value: {p_value}\")\n",
    "\n",
    "t_test_CF_to_DR_ratio_diff = pd.DataFrame({\n",
    "    't_statistic': t_statistic,\n",
    "    'p_value': p_value\n",
    "}, index=[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e04b3686",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create descriptive statistics of VAR state variables of US trad\n",
    "cols = [    \n",
    "    'trad_US',\n",
    "    'BAA10Y',\n",
    "    \"T10Y3M\",\n",
    "    \"DTB3\",\n",
    "    \"CAPE\"\n",
    "]\n",
    "\n",
    "state_variables_descriptives_trad_US = data_VAR_full[cols].describe()\n",
    "\n",
    "state_variables_descriptives_trad_US.loc['autocorr'] = data_VAR_full[cols].apply(lambda x: x.autocorr(), axis=0).T\n",
    "\n",
    "state_variables_descriptives_trad_US.rename(columns={\n",
    "    'trad_US': 'Return US_trad (log)',\n",
    "    'BAA10Y': 'Default Spread',\n",
    "    'T10Y3M': 'Term Spread',\n",
    "    'DTB3': '3M Treasury Bill Rate',\n",
    "    'CAPE': 'CAPE Ratio (log)'\n",
    "}, inplace=True)\n",
    "\n",
    "state_variables_descriptives_trad_US = state_variables_descriptives_trad_US.T.drop(columns=['count']).round(4)\n",
    "\n",
    "# create coefficient table of VAR model for US trad\n",
    "model = VAR(data_VAR_full[cols])\n",
    "\n",
    "res = model.fit(maxlags=1, method='ols', trend='c') # explicitly parametrized, but these are the defaults used in the var_decomposition function\n",
    "\n",
    "res_coefs = pd.DataFrame(\n",
    "    res.coefs[0]\n",
    ")\n",
    "res_constants = pd.DataFrame(\n",
    "    res.intercept\n",
    ")\n",
    "\n",
    "res_basic = pd.concat([res_constants, res_coefs], axis=1)\n",
    "\n",
    "std_errors = pd.DataFrame(res.stderr).T\n",
    "res_basic.columns = std_errors.columns\n",
    "\n",
    "for col in res_basic.columns:\n",
    "    res_basic[f'{col}_stderr'] = std_errors[col].values\n",
    "\n",
    "var_coefficients_trad_US = res_basic.round(4)\n",
    "\n",
    "# calculate R-squared for each equation in the VAR\n",
    "var_r_squared_trad_US = {}\n",
    "for col_name in cols:\n",
    "    actual_values = data_VAR_full[col_name].iloc[res.k_ar:].values\n",
    "    predicted_values = res.fittedvalues[col_name].values\n",
    "    var_r_squared_trad_US[col_name] = r2_score(actual_values, predicted_values)\n",
    "\n",
    "var_r_squared_trad_US = pd.DataFrame.from_dict(var_r_squared_trad_US, orient='index', columns=['R-squared'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3fd4ebb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "#\n",
    "# Other country: JP (robustness)\n",
    "#\n",
    "#\n",
    "cols = [    \n",
    "    'trad_JP',\n",
    "    'BAA10Y',\n",
    "    \"T10Y3M\",\n",
    "    \"DTB3\",\n",
    "    \"CAPE\"\n",
    "]\n",
    "\n",
    "state_variables_descriptives_trad_JP = data_VAR_full[cols].describe()\n",
    "\n",
    "state_variables_descriptives_trad_JP.loc['autocorr'] = data_VAR_full[cols].apply(lambda x: x.autocorr(), axis=0).T\n",
    "\n",
    "state_variables_descriptives_trad_JP.rename(columns={\n",
    "    'trad_JP': 'Return JP_trad (log)',\n",
    "    'BAA10Y': 'Default Spread',\n",
    "    'T10Y3M': 'Term Spread',\n",
    "    'DTB3': '3M Treasury Bill Rate',\n",
    "    'CAPE': 'CAPE Ratio (log)'\n",
    "}, inplace=True)\n",
    "\n",
    "state_variables_descriptives_trad_JP = state_variables_descriptives_trad_JP.T.drop(columns=['count']).round(4)\n",
    "\n",
    "# create coefficient table of VAR model for JP trad\n",
    "model = VAR(data_VAR_full[cols])\n",
    "\n",
    "res = model.fit(maxlags=1, method='ols', trend='c') # explicitly parametrized, but these are the defaults used in the var_decomposition function\n",
    "\n",
    "res_coefs = pd.DataFrame(\n",
    "    res.coefs[0]\n",
    ")\n",
    "res_constants = pd.DataFrame(\n",
    "    res.intercept\n",
    ")\n",
    "\n",
    "res_basic = pd.concat([res_constants, res_coefs], axis=1)\n",
    "\n",
    "std_errors = pd.DataFrame(res.stderr).T\n",
    "res_basic.columns = std_errors.columns\n",
    "\n",
    "for col in res_basic.columns:\n",
    "    res_basic[f'{col}_stderr'] = std_errors[col].values\n",
    "\n",
    "var_coefficients_trad_JP = res_basic.round(4)\n",
    "\n",
    "# calculate R-squared for each equation in the VAR\n",
    "var_r_squared_trad_JP = {}\n",
    "for col_name in cols:\n",
    "    actual_values = data_VAR_full[col_name].iloc[res.k_ar:].values\n",
    "    predicted_values = res.fittedvalues[col_name].values\n",
    "    var_r_squared_trad_JP[col_name] = r2_score(actual_values, predicted_values)\n",
    "\n",
    "var_r_squared_trad_JP = pd.DataFrame.from_dict(var_r_squared_trad_JP, orient='index', columns=['R-squared'])\n",
    "\n",
    "var_r_squared_trad_JP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "316dc653",
   "metadata": {},
   "outputs": [],
   "source": [
    "# including local state variables\n",
    "\n",
    "countries_with_lcl_data = [col[-2:] for col in data_var_full_incl_local_state_vars.columns if col.startswith('CLI_')]\n",
    "result_with_lcl_dict_trad = {}\n",
    "result_with_lcl_dict_csm = {}\n",
    "result_differences = {}\n",
    "for country in countries_with_lcl_data:\n",
    "    df_trad = data_var_full_incl_local_state_vars[[\n",
    "        f\"trad_{country}\",\n",
    "        \"BAA10Y\",\n",
    "        \"T10Y3M\",\n",
    "        \"DTB3\",\n",
    "        \"CAPE\",\n",
    "    ]]\n",
    "\n",
    "    df_with_lcl_trad = data_var_full_incl_local_state_vars[[\n",
    "        f\"trad_{country}\",\n",
    "        \"BAA10Y\",\n",
    "        \"T10Y3M\",\n",
    "        \"DTB3\",\n",
    "        \"CAPE\",\n",
    "        f\"CLI_{country}\"\n",
    "    ]]\n",
    "\n",
    "    df_csm = data_var_full_incl_local_state_vars[[\n",
    "        f\"csm_{country}\",\n",
    "        \"BAA10Y\",\n",
    "        \"T10Y3M\",\n",
    "        \"DTB3\",\n",
    "        \"CAPE\",\n",
    "    ]]\n",
    "\n",
    "    df_with_lcl_csm = data_var_full_incl_local_state_vars[[\n",
    "        f\"csm_{country}\",\n",
    "        \"BAA10Y\",\n",
    "        \"T10Y3M\",\n",
    "        \"DTB3\",\n",
    "        \"CAPE\",\n",
    "        f\"CLI_{country}\"\n",
    "    ]]\n",
    "\n",
    "    trad_N_CF, trad_N_DR, trad_results = var_decomposition.get_var_decomp(df_trad)\n",
    "    trad_N_lcl_CF, trad_N_lcl_DR, trad_lcl_results = var_decomposition.get_var_decomp(df_with_lcl_trad)\n",
    "    csm_N_CF, csm_N_DR, csm_results = var_decomposition.get_var_decomp(df_csm)\n",
    "    csm_N_lcl_CF, csm_N_lcl_DR, csm_lcl_results = var_decomposition.get_var_decomp(df_with_lcl_csm)\n",
    "\n",
    "    trad_corr_mat = np.corrcoef(trad_N_CF, trad_N_DR)\n",
    "    trad_std_N_CF = np.std(trad_N_CF)\n",
    "    trad_std_N_DR = np.std(trad_N_DR)\n",
    "    np.fill_diagonal(trad_corr_mat, [trad_std_N_CF, trad_std_N_DR])\n",
    "    trad_corr_mat_df = pd.DataFrame(trad_corr_mat, index=['CF', 'DR'], columns=['CF', 'DR']).round(4)\n",
    "\n",
    "    trad_lcl_corr_mat = np.corrcoef(trad_N_lcl_CF, trad_N_lcl_DR)\n",
    "    trad_lcl_std_N_CF = np.std(trad_N_lcl_CF)\n",
    "    trad_lcl_std_N_DR = np.std(trad_N_lcl_DR)\n",
    "    np.fill_diagonal(trad_lcl_corr_mat, [trad_lcl_std_N_CF, trad_lcl_std_N_DR])\n",
    "    trad_lcl_corr_mat_df = pd.DataFrame(trad_lcl_corr_mat, index=['CF', 'DR'], columns=['CF', 'DR']).round(4)\n",
    "\n",
    "    csm_corr_mat = np.corrcoef(csm_N_CF, csm_N_DR)\n",
    "    csm_std_N_CF = np.std(csm_N_CF)\n",
    "    csm_std_N_DR = np.std(csm_N_DR)\n",
    "    np.fill_diagonal(csm_corr_mat, [csm_std_N_CF, csm_std_N_DR])\n",
    "    csm_corr_mat_df = pd.DataFrame(csm_corr_mat, index=['CF', 'DR'], columns=['CF', 'DR']).round(4)\n",
    "\n",
    "    csm_lcl_corr_mat = np.corrcoef(csm_N_lcl_CF, csm_N_lcl_DR)\n",
    "    csm_lcl_std_N_CF = np.std(csm_N_lcl_CF)\n",
    "    csm_lcl_std_N_DR = np.std(csm_N_lcl_DR)\n",
    "    np.fill_diagonal(csm_lcl_corr_mat, [csm_lcl_std_N_CF, csm_lcl_std_N_DR])\n",
    "    csm_lcl_corr_mat_df = pd.DataFrame(csm_lcl_corr_mat, index=['CF', 'DR'], columns=['CF', 'DR']).round(4)\n",
    "\n",
    "\n",
    "    # differences between news vectors\n",
    "    trad_std_N_CF_diff = np.std(np.array(trad_N_CF) - np.array(trad_N_lcl_CF))\n",
    "    trad_std_N_DR_diff = np.std(np.array(trad_N_lcl_DR) - np.array(trad_N_DR))\n",
    "    csm_std_N_CF_diff = np.std(np.array(csm_N_lcl_CF) - np.array(csm_N_CF))\n",
    "    csm_std_N_DR_diff = np.std(np.array(csm_N_lcl_DR) - np.array(csm_N_DR))    \n",
    "\n",
    "    result_with_lcl_dict_trad[country] = {\n",
    "        'cash flow': trad_lcl_std_N_CF,\n",
    "        'discount_rate': trad_lcl_std_N_DR\n",
    "    }\n",
    "\n",
    "    result_with_lcl_dict_csm[country] = {\n",
    "        'cash flow': csm_lcl_std_N_CF,\n",
    "        'discount_rate': csm_lcl_std_N_DR\n",
    "    }\n",
    "\n",
    "    result_differences[country] = {\n",
    "        'trad_std_N_CF_diff': trad_std_N_CF_diff,\n",
    "        'trad_std_N_DR_diff': trad_std_N_DR_diff,\n",
    "        'csm_std_N_CF_diff': csm_std_N_CF_diff,\n",
    "        'csm_std_N_DR_diff': csm_std_N_DR_diff\n",
    "    }\n",
    "\n",
    "    # result_dict[country] = {\n",
    "    #     'trad': {\n",
    "    #         'corr_matrix': trad_corr_mat_df,\n",
    "    #         # 'N_CF': trad_N_CF,\n",
    "    #         # 'N_DR': trad_N_DR,\n",
    "    #         # 'results': trad_results\n",
    "    #     },\n",
    "    #     'csm': {\n",
    "    #         'corr_matrix': csm_corr_mat_df,\n",
    "    #         # 'N_CF': csm_N_CF,\n",
    "    #         # 'N_DR': csm_N_DR,\n",
    "    #         # 'results': csm_results\n",
    "    #     }\n",
    "    # }\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ed44a6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for country in result_with_lcl_dict_trad.keys():\n",
    "#     print(f\"Country: {country}\")\n",
    "#     print(\"Traditional Index:\")\n",
    "#     print(pd.DataFrame([\n",
    "#             result_with_lcl_dict_trad[country],\n",
    "#             result_with_lcl_dict_csm[country]\n",
    "#     ], index=['Traditional', 'CSM']))\n",
    "\n",
    "\n",
    "for country in result_differences.keys():\n",
    "    print(f\"Country: {country}\")\n",
    "    print(pd.DataFrame([\n",
    "            result_differences[country]\n",
    "    ], index=[\" \"]).T)\n",
    "    print( ) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "675ee1dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_to_export = {\n",
    "    'long_run_corr_results': long_run_corr_results,\n",
    "    'mean_variance_frontiers': mean_variance_frontiers,\n",
    "    'spanning_results_separate_regressions_results': spanning_results_separate_regressions_results,\n",
    "    'spanning_results_multivariate_per_country_GRS': spanning_results_multivariate_per_country_GRS,\n",
    "    'state_variables_descriptives_trad_US': state_variables_descriptives_trad_US,\n",
    "    'var_coefficients_trad_US': var_coefficients_trad_US,\n",
    "    'var_r_squared_trad_US': var_r_squared_trad_US,\n",
    "    'state_variables_descriptives_trad_JP': state_variables_descriptives_trad_JP,\n",
    "    'var_coefficients_trad_JP': var_coefficients_trad_JP,\n",
    "    'var_r_squared_trad_JP': var_r_squared_trad_JP,\n",
    "    'var_decomp_summary': df_combined,\n",
    "    't_test_CF_to_DR_ratio_diff': t_test_CF_to_DR_ratio_diff,    \n",
    "    'var_decomp_results_global': var_decomp_results_global,\n",
    "}\n",
    "\n",
    "with open('rmarkdown/run4-mimicking_addl.pkl', 'wb') as f:\n",
    "    pickle.dump(data_to_export, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48f447c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "### convert output to csv's for easier use in R markdown\n",
    "\n",
    "\n",
    "# write dataframes in nested dicts to csv\n",
    "for k, v in data_to_export.items():\n",
    "    if isinstance(v, pd.DataFrame):\n",
    "        v.to_csv(f'{output_path}/{k}.csv')\n",
    "    elif isinstance(v, dict):\n",
    "        for k2, v2 in v.items():\n",
    "            if isinstance(v2, pd.DataFrame):\n",
    "                v2.to_csv(f'{output_path}/{k}_{k2}.csv')            \n",
    "            elif isinstance(v2, dict):\n",
    "                for k3, v3 in v2.items():\n",
    "                    if isinstance(v3, pd.DataFrame):\n",
    "                        v3.to_csv(f'{output_path}/{k}_{k2}_{k3}.csv')\n",
    "                    else:\n",
    "                        print(f'warning! incomplete export for {k}, {k2}, {k3}')\n",
    "            else:\n",
    "                print(f'warning! incomplete export for {k}, {k2}')\n",
    "    else:\n",
    "        print(f'warning! incomplete export for {k}')\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb76d4dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "COUNTRIES_OF_INTEREST\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py313",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
