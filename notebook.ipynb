{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4147b6da",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Initialize, import libraries and load data \"\"\"\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "\n",
    "import statsmodels.api as sm\n",
    "\n",
    "data_path = 'data/index_data/'  \n",
    "\n",
    "# load data\n",
    "with open(data_path + 'run4-mimicking.pkl', 'rb') as f:\n",
    "    results = pickle.load(f)\n",
    "\n",
    "trad_country_returns = results[\"trad_country_returns\"]\n",
    "csm_returns = results[\"csm_returns\"]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0c6c9a0",
   "metadata": {},
   "source": [
    "This section provides mean-variance spanning tests (Huberman and Kandel, 1988). This methodology has previously been applied in the context of international diversification. Mean-variance spanning works by selecting a set of initial asset, commonly called benchmark assets. Next to that, there are test assets. Mean-variance spanning provides an answer to the question of whether the mean-variance efficient frontier of the test assets is the same as that of the benchmark assets.\n",
    "\n",
    "Huberman and Kandel's (HK) approach is that of a regression:\n",
    "\n",
    "Y = a + bX + e\n",
    "\n",
    "Where Y is an N x t matrix of returns of test assets; X is a K x t matrix of returns of benchmark assets; a is 1 x K vector of intercepts coefficients and b a 1 x K vector of coefficients. [look at dimensions; do not yet match!]\n",
    "\n",
    "The HK test looks at the intercepts - in the case where the two mean-variance frontiers are the same, the intercepts will also be 0. Or put differently, when the intercepts are not statistically significant from zero, we can infer that the mean-variance frontier of the test assets is not significantly different from that of the benchmark assets. This, in turn, implies that there are no diversification benefits from adding the test assets.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc3b1016",
   "metadata": {},
   "source": [
    "First we perform iterative mean spanning tests, where have as N benchmark assets the traditional country indices; and each time, we add a different test asset K to the mix. In these cases, K is always 1. The set of K test assets to draw from is the set of individual CSM country indices."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5faaf694",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb8d0cfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "spanning_results = {}\n",
    "X = sm.add_constant(trad_country_returns)\n",
    "for country in csm_returns.columns:\n",
    "    y = csm_returns[country]\n",
    "    model = sm.OLS(y, X).fit()\n",
    "    spanning_results[country] = model\n",
    "\n",
    "for test_asset, model in spanning_results.items():\n",
    "    print(f\"Results for CSM index country: {test_asset}\")\n",
    "    print(model.summary())\n",
    "    print(\"\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35987897",
   "metadata": {},
   "source": [
    "The regression below presents the entire model. This is a multivariate model, meaning the lhs of the equation consists of all the test assets (N x t). In order to facilitate the regression tooling software, the data were transformed so that the dependent variable was one long vector of all the columns {r1, ..., rN} of the original matrix R.\n",
    "\n",
    "R -> [r1, r2, r3]'\n",
    "\n",
    "Its dimensions are now (N x t) x 1\n",
    "\n",
    "On the righthand side, the benchmark asset returns were 'repeated' so as to properly match the dependent variable data and new dimensions. The block of R (N x K) was extended N times. So that the dimensions are now (t x N) x K. Previously the shape was N x K.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6822106f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combined model:\n",
    "y_combined = csm_returns.values.flatten()\n",
    "X_combined = np.tile(\n",
    "    trad_country_returns.values, \n",
    "    (csm_returns.shape[1], 1)\n",
    ")\n",
    "X_combined = sm.add_constant(X_combined)\n",
    "\n",
    "combined_model = sm.OLS(y_combined, X_combined).fit()\n",
    "print(combined_model.summary())\n",
    "\n",
    "# f_test_result = combined_model.f_test(\"const = 0\")\n",
    "# print(f_test_result.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a315f39a",
   "metadata": {},
   "source": [
    "The model shows that the regression coefficient of the intercept is different from zero with statistical significance (p < 0.001). The result that not all coefficients are (near) zero suggests that the benchmark assets cannot span the total return variance of test assets and therefore, that there are diversification benefits of the CSM indices.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36e2dbca",
   "metadata": {},
   "source": [
    "# Efficient frontier\n",
    "We can also visualize the efficient frontiers for portfolios constructed using either country index. We construct the efficient frontier as follows. We find a set of weights w such that for various levels of returns, we minimize the volatility of the portfolio:\n",
    "\n",
    "min (w'Sw)^(1/2)\n",
    "\n",
    "s.t. sum(w) = 1\n",
    "and 0 <= w_i <= 1\n",
    "\n",
    "where w is an 1 x N vector of weights, for N number of countries and S is the N x N sample covariance matrix. The covariance matrix is constructed by simply taking the entire range of monthly returns for each asset. The returns are therefore in monthly terms, which is a bit odd to interpret but does not change the essence of the frontiers.\n",
    "\n",
    "We perform this exercise twice, once for the CSM indices and again for the traditional country indices. We can then compare the shape of the two."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3e79a0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import create_efficient_frontier\n",
    "\n",
    "csm_mean_returns = csm_returns.mean().values\n",
    "csm_cov_matrix = csm_returns.cov()\n",
    "\n",
    "trad_mean_returns = trad_country_returns.mean().values\n",
    "trad_cov_matrix = trad_country_returns.cov()\n",
    "\n",
    "# combined_returns = pd.concat([csm_returns, trad_country_returns], axis=1)\n",
    "# combined_mean_returns = combined_returns.mean().values\n",
    "# combined_cov_matrix = combined_returns.cov()\n",
    "\n",
    "ef_csm = create_efficient_frontier(csm_mean_returns, csm_cov_matrix)\n",
    "ef_trad = create_efficient_frontier(trad_mean_returns, trad_cov_matrix)\n",
    "# ef_combined = create_efficient_frontier(combined_mean_returns, combined_cov_matrix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02929a11",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(ef_csm.volatility * 100, ef_csm.returns * 100, label='Efficient Frontier csm', color='blue', linestyle='-')\n",
    "plt.plot(ef_trad.volatility * 100, ef_trad.returns * 100, label='Efficient Frontier trad', color='red', linestyle='-')\n",
    "# plt.plot(ef_combined.volatility * 100, ef_combined.returns * 100, label='Efficient Frontier combined', color='green', linestyle='--')\n",
    "plt.xlabel('Portfolio Volatility (Std. Dev.)')\n",
    "plt.ylabel('Portfolio Return')\n",
    "plt.title('Efficient Frontier')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eddbe6f0",
   "metadata": {},
   "source": [
    "# Monte Carlo simulations\n",
    "This section explores the diversification properties of the CSM indices versus their traditional country proponents using Monte Carlo simulations. For both index types (csm and trad) we randomly sample countries to construct portfolios. For each simulation run, we vary the number of countries we draw. So we randomly draw 2 countries, 3 countries, 5 countries, etc. Each draw, we calculate the equal-weighted portfolio returns of the sampled countries and calculate annualized (geometric) return, standard deviation of the returns and risk/reward ratio (the ratio of the first two metrics - called the Sharpe ratio in the graph, although it is technically not so). This is repeated 10.000 times. We repeat this procedure for specific numbers of countries (2, 3, 5, 7, 10, 13, 16) and for both index types. We finally proceed to aggregate the results by retaining only specific points from the obtained distribution. For each set of outcomes of 10.000 runs we select only the 2.5 percentile, 97.5 percentile and the median observations. \n",
    "\n",
    "The results are shown in the graphs below. The first panel shows only the median results for both index types, in one graph. The second panel also presents the lower (2.5 percentile) and upper (97.5 percentile) ranges of the distribution of the results. They are shown in separate plots for clarity. The third panel presents the results for the risk/reward ratio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e98dc843",
   "metadata": {},
   "outputs": [],
   "source": [
    "import simulations\n",
    "\n",
    "# load data\n",
    "results_quantiles = pd.read_csv('data/simulations_results_quantiles_n_runs_10000.csv', index_col=0)\n",
    "\n",
    "simulations.plot_std_dev(results_quantiles, metric=\"std_dev\", n_runs=10000, list_of_quantiles=[0.5], facet_plot=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33b30d7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import simulations\n",
    "\n",
    "# load data\n",
    "results_quantiles = pd.read_csv('data/simulations_results_quantiles_n_runs_10000.csv', index_col=0)\n",
    "\n",
    "simulations.plot_std_dev(results_quantiles, metric=\"std_dev\", n_runs=10000, list_of_quantiles=None, facet_plot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa0e6359",
   "metadata": {},
   "outputs": [],
   "source": [
    "import simulations\n",
    "\n",
    "# load data\n",
    "results_quantiles = pd.read_csv('data/simulations_results_quantiles_n_runs_10000.csv', index_col=0)\n",
    "\n",
    "simulations.plot_std_dev(results_quantiles, metric=\"sharpe_ratio\", n_runs=10000, list_of_quantiles=None, facet_plot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b955386",
   "metadata": {},
   "source": [
    "We can visually interpret these results as follows. Let's first look at the change in standard deviation as the number of countries in portfolio increases. We are not directly interested in absolute levels (these are slightly higher on average for CSM indices), we want to look at the shape of each graph and compare that. So this graph, for the CSM indices, starts at around 6.8% (for 2 countries) and ends at 5.9%. This is a decrease of 14%. For the trad indices, the curve starts at 6% (for 2 countries) and ends at 5.4%. This is a decrease of 10%. Moreover, the curve for the traditional country indices seems to be slightly more concave, meaning it approaches the asymptote faster. \n",
    "\n",
    "These results suggests that the diversification benefits of traditional country indices are depleted faster. It takes fewer different countries in the index to obtain a decrease in portfolio risk similar to holding all countries. A flipside of this observation is that one could say that these traditional country indices are more alike. For the CSM indices, it takes more countries to approximate the portfolio standard deviation of the full set of countries. This suggests that CSM indices are more different from one another than traditional country indices are.\n",
    "\n",
    "The statistics mentioned above in the text are summarized in the table below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a828f96",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_quantiles = pd.read_csv('data/simulations_results_quantiles_n_runs_10000.csv', index_col=0)\n",
    "csm_median_stddev_start = results_quantiles[(results_quantiles['dataset'] == 'csm') & (results_quantiles.index == 0.5) & (results_quantiles['num_countries'] == 2)]['std_dev']\n",
    "csm_median_stddev_end = results_quantiles[(results_quantiles['dataset'] == 'csm') & (results_quantiles.index == 0.5) & (results_quantiles['num_countries'] == 16)]['std_dev']\n",
    "\n",
    "trad_median_stddev_start = results_quantiles[(results_quantiles['dataset'] == 'trad') & (results_quantiles.index == 0.5) & (results_quantiles['num_countries'] == 2)]['std_dev']\n",
    "trad_median_stddev_end = results_quantiles[(results_quantiles['dataset'] == 'trad') & (results_quantiles.index == 0.5) & (results_quantiles['num_countries'] == 16)]['std_dev']\n",
    "\n",
    "pd.DataFrame({\n",
    "    'CSM': \n",
    "    {\n",
    "        'median_stddev_start (N=2)': csm_median_stddev_start.values[0],\n",
    "        'median_stddev_end (N=16)': csm_median_stddev_end.values[0],\n",
    "        'relative_change': csm_median_stddev_end.values[0] / csm_median_stddev_start.values[0] - 1\n",
    "    },\n",
    "    'Traditional': \n",
    "    {\n",
    "        'median_stddev_start (N=2)': trad_median_stddev_start.values[0],\n",
    "        'median_stddev_end (N=16)': trad_median_stddev_end.values[0],\n",
    "        'relative_change': trad_median_stddev_end.values[0] / trad_median_stddev_start.values[0] - 1\n",
    "    }\n",
    "})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f739cc4",
   "metadata": {},
   "source": [
    "# Section: return decomposition\n",
    "\n",
    "In this section we explore more closely the return characteristics of the CSM indices. Given that a CSM index is, by design, more closely linked to its sales footprint to a given country (and therefore by its cashflows), we formulate the expectation that the returns are more closely linked to news about cashflows than discount rates - or at least to cashflow news relating to the target country. This point is not trivial and we will develop that in more detail later. In order to test this hypothesis, we will perform a return decomposition of both the CSM indices and traditional country indices, so that we may compare the results. \n",
    "\n",
    "An established procedure to study this phenomenon, is through the present value decomposition of excess returns (Shiller and Campbell, 1988), through a vector autoregressive model (Campbell, 1991). This approach has been applied, in many variations, to several research questions in the literature (/cite).\n",
    "\n",
    "The methodology has its origins in present value models that show that the present value of an asset will be determined by two main components: (1) it will change with unexpected information/news about the cashflows from the asset. If expected cashflows go down, naturally, the value of the asset will go down as well, and vice versa; (2) it will change with the discount rate. If the discount rate with which the cashflows are valued goes down, future cashflows become more valuable. Therefore, the value of the asset will rise. An important distinction between the two components is that a change in discount rates will have an effect on the asset's value now, but also on the expected future return: as the discount rate goes down, initially the value of the asset will rise, but the future expected return will move in the other direction. For news about cashflows, this phenomenon does not occur. Positive (negative) cashflow news will simply lead to a one-off increase (decrease) in the asset's price.\n",
    "\n",
    "An important thing to note here is that we are talking about _expectations_. The rationale behind focusing on news (sometimes also called innovations) is that only new information will move prices. The (reasonable) assumption is that everything that is already known should be reflected in today's market prices.\n",
    "\n",
    "Campbell and Shiller's (1988a) original approach to formalize this notion was into the following seminal equation:\n",
    "\n",
    "r_{t+1} - E_t r_{t+1} = ...\n",
    "\n",
    "r_{t+1} - E_t r_{t+1} = N_{CF, t+1} - N_{DR, t+1}\n",
    "\n",
    "where N_CF denotes news about future cash flows, N_DR denotes news about future discount rates.\n",
    "\n",
    "This equation can be operationalized using Campbell's (1991) VAR approach. The VAR model is designed such that it first estimates the terms Et r_{T+1} (today's expectation of next period returns) and (E_{t+1} - E_t)\\sum(rho x r_{t+i+j}) (news about future discount rates). This gives us two of the three terms of equation 2; and we can calculate the remaining term N_{CF}. \n",
    "\n",
    "As in Campbell and Polk (2002), we assume the data generating process comes from the following VAR model:\n",
    "\n",
    "z_{t+1} = a + X z_{t} + u_{t+1}\n",
    "\n",
    "where z_{t+1} is an m x 1 state vector, a and X are constant parameters with dimensions of m x 1 respectively m x m; and u_{t+1} an i.i.d. m x 1 vector of shocks. The crux of the VAR model lies in the u_{t+1} vector. They are based on the residuals of the model and account for all variance of the asset's return that is not explained by the system of (lagged) state variables. This is important to note, as it underlines the importance of having the state variables correct. One characteristic of these types of VAR models is that the convention is that the first equation is always the lagged (one-period) return. This means the first element of z_{t+1} is r_{t+1}.\n",
    "\n",
    "In order to get from aggregate shocks to news on specifically cashflows and/or discount rates, we use the following mapping functions:\n",
    "\n",
    "N_{CF, t+1) = ... \n",
    "N_{DR, t+1) = ...\n",
    "\n",
    "Where e1 is a vector of length m with 1 as its first element and 0's otherwise. This effectively selects only the first row (return component) to measure news sensitivity. \\lambda is defined as \\lambda = \\rho X(I - \\rho X)^-1. \n",
    "\n",
    "# State variables\n",
    "There has been quite some variation in the literature on which state variables have been used (see Driessen en Van Zundert (2017) for an overview). As a starting point, we will use those that are commonly used in the literature. But we have to be cautious with using certain holdings / fundamentally based equity criteria. A state variable that is often used is the price/earnings ratio (of which there exist many variations). These are measured on an index level. For the US, the Shiller PE, which is publically available from Prof. Shiller's website, is commonly used. This US Shiller PE is based on price, dividends, earnings and inflation of the S&P500 index. However, for our research question, that may not be a suitable approach, since it is a very close manifestation of the traditional country index we are comparing the CSM index for the US against. Therefore, we will rely mostly on macro-economic factors of a country.\n",
    "\n",
    "There still is some value in performing the analysis using P/E ratio's, but we will only do this as a robustness check (and we have to be cautious interpreting the results). We will use two variations. One using the US CAPE ratio. Another using a global price/earnings ratio, derived from a global market index. The downsides of the first were already mentioned. The latter approach, using global P/E's, also comes with a downside, which is that it contains information that is not directly relevant to the specific country. If either traditional country indices or CSM indices are a substantially better proxy for a target country's risk, using global fundamentals may not be the best way to measure that. A benefit of using global fundamentals is that it can easily be applied to any country index.\n",
    "\n",
    "\n",
    "# Data\n",
    "In this initial version, we will focus on one country: the US. For this country, we are certain that we can find appropriate data.\n",
    "\n",
    "Suitable are:\n",
    "* Excess stock return\n",
    "* 1M t-bill rate\n",
    "* Yield spread (10Y-3M)\n",
    "* Default spread\n",
    "\n",
    "Robustness:\n",
    "* Shiller PE (US and global)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py313",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
